= Analysis
include::_attributes.adoc[]

[#analysis-overview]
== Analysis Overview

When performing upgrades of services there is a need to test the new version
that is being deployed to ensure functionality is not being negatively impacted. The
link:https://argo-rollouts.readthedocs.io/en/stable/features/analysis[Analysis,window='_blank'] feature
enables Rollouts to collect data and metrics from a variety of providers to validate the
new version of the application.

In addition to collecting data, an Analysis can include a Job to drive more advanced use cases. For example
a Job could be used to run load against an application in order to generate the metrics needed to
validate the revision.

To deploy an Analysis, first an AnalysisTemplate is created that defines the analysis that is required
and then is associated with one or more rollouts. The association with the rollout is dependent one
the rollout strategy used. In this module we will look at it from the perspective of the Blue-Green
strategy we have deployed however in the next module we delve into it for the Canary strategy as well.

In the blue-green strategy, an Analysis can be added as either pre-promotion or post-promotion. Pre-promotion
is used before the new version is deployed and is useful for validating the deployment prior to cutting over to it
for live traffic. Post-promotion is executed after the cut-over and can validate that the deployment is working
with live traffic.

[#analysis-deployment]
== Analysis Deployment

In this section we will deploy the same Blue-Green rollout we did previously but with
a pre-promotion analysis included along with the corresponding analysis template. Prior to starting,
confirm you are still at the correct path.

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
cd ~/argo-rollouts-workshop/documentation/modules/ROOT/examples/
----

Next, let's explore the manifests that we will be deploying in the `./bluegreen-analysis/base` folder:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
ls ./bluegreen-analysis/base
----

Here you will see the same files that we used previously, however there is a new file `analysistemplate.yaml`. Examining
the file we see it appears as follows:

.link:https://github.com/OpenShiftDemos/argo-rollouts-workshop/blob/main/documentation/modules/ROOT/examples/bluegreen-analysis/base/analysistemplate.yaml[./bluegreen-analysis/base/analysistemplate.yaml,window='_blank']
[source,yaml,subs="+macros,attributes+"]
----
include::ROOT:example$bluegreen-analysis/base/analysistemplate.yaml[]
----

This AnalysisTemplate is broken up into two broad sections as follows:

* `.spec.args`. This is where you can specify arguments which are passed by the rollout when using the template. These arguments
enable the template to be reusable across many different rollouts.
* `.spec.metrics`. These are the metric providers that will be used to collect data for the analysis as well as any jobs
that need to be executed.

In the metrics provider section we can see we have two providers defined, one that uses the web metric provider to pull
metrics from Thanos, an aggregator for Prometheus data, and a job that runs link:https://github.com/JoeDog/siege[Apache Siege,window='_blank']
to drive some load on the application.

[NOTE]
We are using the web metric provider here since Argo Rollouts does not currenly support authentication with the Prometheus
provider. This is one of the gaps that Red Hat is planning on closing prior to supporting Rollouts in OpenShift GitOps
as a Generally Available (GA) product.

Remember we are running this Analysis in the pre-promotion phase of the blue-green strategy so the application will not
be receiving load from users, therefore generating load with Apache Siege will generate the metrics we need to determine whether
the promotion should proceed.

In the arguments we are taking two key arguments, `query` and `route-url`, which will be passed from the
Rollout. Notice that the `query` argument is being used at the end of the URL of the web provider as a
query parameter, this is the Prometheus query that we want to execute against the OpenShift monitoring stack.

[subs="quotes"]
----
provider:
  web:
    url: https://thanos-querier.openshift-monitoring:9091/api/v1/query?query={{ *args.query* }}
----

The `route-url` parameter is being used in the second provider, the job, where we will be creating load. This
parameter is used to specify the OpenShift route URL where we want to drive the load, i.e the URL that
siege will be hitting when it generates load.

Finally a third parameter, `api-token`, is provided by a secret. This secret provides a token needed to access the OpenShift monitoring
stack, it was created by the GitOps process which provisioned this workshop.

Next let's look at the rollout and see how the AnalysisTemplate is wired into the rollout.

.link:https://github.com/OpenShiftDemos/argo-rollouts-workshop/blob/main/documentation/modules/ROOT/examples/bluegreen-analysis/base/rollout.yaml[./bluegreen-analysis/base/rollout.yaml,window='_blank']
[source,yaml,subs="+macros,attributes+"]
----
include::ROOT:example$bluegreen-analysis/base/rollout.yaml[]
----

Notice that in `.spec.strategy.blueGreen` we have now defined the `prePromotionAnalysis` field. In this field
we define the template we want to use as well as the arguments that the rollout needs to provide the
analysis template.

[Note]
The query parameter is URL encoded since we are using the web provider rather then the prometheus
provider hence the odd encoding.

Prior to deploying the rollout we need to fetch the URL for the preview service so we can
replace the token in the route-url argument in the rollout.

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
export PREVIEW_ROUTE=$(oc get route -n user%USERNUM%-prod preview -o jsonpath='{"https://"}{.spec.host}{"\n"}')
----

Next to deploy this new version of the blue-green rollout, execute the following command:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
kustomize build ./bluegreen-analysis/base | sed 's/$PREVIEW_ROUTE/%PREVIEW_ROUTE%/'| oc apply -n user%USERNUM%-prod -f -
----
